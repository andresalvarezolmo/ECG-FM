{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# Electrocardiogram Analysis using ECG-FM\n",
    "\n",
    "The electrocardiogram (ECG) is a low-cost, non-invasive diagnostic test that has been ubiquitous in the assessment and management of cardiovascular disease for decades. ECG-FM is a pretrained, open foundation model for ECG analysis.\n",
    "\n",
    "In this tutorial, we will introduce how to perform inference for multi-label classification using a finetuned ECG-FM model. Specifically, we will take a model finetuned on the [PhysioNet 2021 v1.0.3 dataset](https://physionet.org/content/challenge-2021/1.0.3/) and perform inference on a sample of the [CODE-15% v1.0.0 dataset](https://zenodo.org/records/4916206/) to show how to adapt the predictions to a new set of labels.\n",
    "\n",
    "## Overview\n",
    "0. Installation\n",
    "1. Prepare checkpoints\n",
    "2. Prepare data\n",
    "3. Run inference\n",
    "4. Interpret results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2",
   "metadata": {},
   "source": [
    "## 0. Installation\n",
    "\n",
    "ECG-FM was developed in collaboration with the [fairseq_signals](https://github.com/Jwoo5/fairseq-signals) framework, which implements a collection of deep learning methods for ECG analysis.\n",
    "\n",
    "Clone [fairseq_signals](https://github.com/Jwoo5/fairseq-signals) and refer to the requirements and installation section in the top-level README. After following those steps, install `pandas` and make the environment accessible within this notebook by running:\n",
    "```\n",
    "python3 -m pip install --user pandas\n",
    "python3 -m pip install --user --upgrade jupyterlab ipywidgets ipykernel\n",
    "python3 -m ipykernel install --user --name ecg_fm\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "\n",
    "from fairseq_signals.utils.store import MemmapReader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4",
   "metadata": {},
   "outputs": [],
   "source": [
    "root = '/Users/andresalvarezolmo/Documents/hume/ACS/playground/ECG-FM'\n",
    "root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "fairseq_signals_root = '/Users/andresalvarezolmo/Documents/hume/ACS/playground/fairseq-signals'\n",
    "fairseq_signals_root = fairseq_signals_root.rstrip('/')\n",
    "fairseq_signals_root"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "## 1. Prepare checkpoints"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "### Download checkpoints\n",
    "\n",
    "The checkpoints are available on [HuggingFace](https://huggingface.co/wanglab/ecg-fm-preprint). Alternatively, they can be downloaded using the below commands.\n",
    "\n",
    "**Disclaimer: These models are different from those reported in our arXiv paper.** These BERT-Base sized models were trained purely on public data sources due to privacy concerns surrounding UHN-ECG data and patient identification. Validation for the final models will be available upon full publication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "_ = hf_hub_download(\n",
    "    repo_id='wanglab/ecg-fm-preprint',\n",
    "    filename='physionet_finetuned.pt',\n",
    "    local_dir=os.path.join(root, 'notebooks/ckpts'),\n",
    ")\n",
    "_ = hf_hub_download(\n",
    "    repo_id='wanglab/ecg-fm-preprint',\n",
    "    filename='physionet_finetuned.yaml',\n",
    "    local_dir=os.path.join(root, 'notebooks/ckpts'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(os.path.join(root, 'notebooks/ckpts/physionet_finetuned.pt'))\n",
    "assert os.path.isfile(os.path.join(root, 'notebooks/ckpts/physionet_finetuned.yaml'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10",
   "metadata": {},
   "source": [
    "## 2. Prepare data\n",
    "\n",
    "The model being used was finetuned on the [PhysioNet 2021 v1.0.3 dataset](https://physionet.org/content/challenge-2021/1.0.3/). To simplify this tutorial, we have processed a sample of 10 ECGs (14 5s segments) from the [CODE-15% v1.0.0 dataset](https://zenodo.org/records/4916206/) so that we may demonstrate how to adapt the predictions to a new set of labels.\n",
    "\n",
    "If looking to perform inference on a full dataset (or using your own dataset), refer to the flexible, end-to-end, multi-source data preprocessing pipeline described [here](https://github.com/Jwoo5/fairseq-signals/tree/master/scripts/preprocess/ecg). Its README is useful for understanding how the data is organized. There are preprocessing scripts implemented for several datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11",
   "metadata": {},
   "source": [
    "### Update manifest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {},
   "source": [
    "The segmented split must be saved with absolute file paths, so we will update the current relative file paths accordingly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {},
   "outputs": [],
   "source": [
    "segmented_split = pd.read_csv(\n",
    "    os.path.join(root, 'data/code_15/segmented_split_incomplete.csv'),\n",
    "    index_col='idx',\n",
    ")\n",
    "segmented_split['path'] = (root + '/data/code_15/segmented/') + segmented_split['path']\n",
    "segmented_split.to_csv(os.path.join(root, 'data/code_15/segmented_split.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(os.path.join(root, 'data/code_15/segmented_split.csv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15",
   "metadata": {},
   "source": [
    "Run the follow commands togenerate the `test.tsv` file used for inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {},
   "outputs": [],
   "source": [
    "cmd = f\"\"\"\n",
    "cd {fairseq_signals_root}/scripts/preprocess && \\\n",
    "python manifests.py \\\n",
    "    --split_file_paths \"{root}/data/code_15/segmented_split.csv\" \\\n",
    "    --save_dir \"{root}/data/manifests/code_15_subset10/\"\n",
    "\"\"\"\n",
    "os.system(cmd)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(os.path.join(root, 'data/manifests/code_15_subset10/test.tsv'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {},
   "source": [
    "## 3. Run inference\n",
    "\n",
    "Inside our environment, we can run the following command using hydra's command line interface to extract the logits for each segment. There must be an available GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {},
   "outputs": [],
   "source": [
    "inference_cmd = f\"\"\"fairseq-hydra-inference \\\\\n",
    "    task.data=\"{root}/data/manifests/code_15_subset10/\" \\\\\n",
    "    common_eval.path=\"{root}/notebooks/ckpts/physionet_finetuned.pt\" \\\\\n",
    "    common_eval.results_path=\"{root}/outputs\" \\\\\n",
    "    model.num_labels=26 \\\\\n",
    "    dataset.valid_subset=\"test\" \\\\\n",
    "    dataset.batch_size=10 \\\\\n",
    "    dataset.num_workers=3 \\\\\n",
    "    dataset.disable_validation=false \\\\\n",
    "    distributed_training.distributed_world_size=1 \\\\\n",
    "    distributed_training.find_unused_parameters=True \\\\\n",
    "    --config-dir \"{root}/notebooks/ckpts\" \\\\\n",
    "    --config-name physionet_finetuned\n",
    "\"\"\"\n",
    "\n",
    "os.system(inference_cmd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {},
   "outputs": [],
   "source": [
    "assert os.path.isfile(os.path.join(root, 'outputs/outputs_test.npy'))\n",
    "assert os.path.isfile(os.path.join(root, 'outputs/outputs_test_header.pkl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21",
   "metadata": {},
   "source": [
    "## 4. Interpret results\n",
    "\n",
    "The logits are ordered same as the samples in the manifest and labels in the label definition."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {},
   "source": [
    "### Get predictions on PhysioNet 2021 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {},
   "outputs": [],
   "source": [
    "physionet2021_label_def = pd.read_csv(\n",
    "    os.path.join(root, 'data/physionet2021/labels/label_def.csv'),\n",
    "     index_col='name',\n",
    ")\n",
    "physionet2021_label_names = physionet2021_label_def.index\n",
    "physionet2021_label_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the array of computed logits\n",
    "logits = MemmapReader.from_header(\n",
    "    os.path.join(root, 'outputs/outputs_test.npy')\n",
    ")[:]\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct predictions from logits\n",
    "pred = pd.DataFrame(\n",
    "    torch.sigmoid(torch.tensor(logits)).numpy(),\n",
    "    columns=physionet2021_label_names,\n",
    ")\n",
    "\n",
    "# Join in sample information\n",
    "pred = segmented_split.reset_index().join(pred, how='left').set_index('idx')\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform a (crude) thresholding of 0.5 for all labels\n",
    "pred_thresh = pred.copy()\n",
    "pred_thresh[physionet2021_label_names] = pred_thresh[physionet2021_label_names] > 0.5\n",
    "\n",
    "# Construct a readable column of predicted labels for each sample\n",
    "pred_thresh['labels'] = pred_thresh[physionet2021_label_names].apply(\n",
    "    lambda row: ', '.join(row.index[row]),\n",
    "    axis=1,\n",
    ")\n",
    "pred_thresh['labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27",
   "metadata": {},
   "source": [
    "### Map predictions to CODE-15 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_15_label_def = pd.read_csv(\n",
    "    os.path.join(root, 'data/code_15/labels/label_def.csv'),\n",
    "     index_col='name',\n",
    ")\n",
    "code_15_label_names = code_15_label_def.index\n",
    "code_15_label_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_mapping = {\n",
    "    'CRBBB|RBBB': 'RBBB',\n",
    "    'CLBBB|LBBB': 'LBBB',\n",
    "    'SB': 'SB',\n",
    "    'STach': 'ST',\n",
    "    'AF': 'AF',\n",
    "}\n",
    "\n",
    "physionet2021_label_def['name_mapped'] = physionet2021_label_def.index.map(label_mapping)\n",
    "physionet2021_label_def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_mapped = pred.copy()\n",
    "pred_mapped.drop(set(physionet2021_label_names) - set(label_mapping.keys()), axis=1, inplace=True)\n",
    "pred_mapped.rename(label_mapping, axis=1, inplace=True)\n",
    "pred_mapped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_thresh_mapped = pred_thresh.copy()\n",
    "pred_thresh_mapped.drop(set(physionet2021_label_names) - set(label_mapping.keys()), axis=1, inplace=True)\n",
    "pred_thresh_mapped.rename(label_mapping, axis=1, inplace=True)\n",
    "pred_thresh_mapped['predicted'] = pred_thresh_mapped[label_mapping.values()].apply(\n",
    "    lambda row: ', '.join(row.index[row]),\n",
    "    axis=1,\n",
    ")\n",
    "pred_thresh_mapped"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32",
   "metadata": {},
   "source": [
    "### Compare predicted CODE-15 to actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {},
   "outputs": [],
   "source": [
    "code_15_labels = pd.read_csv(os.path.join(root, 'data/code_15/labels/labels.csv'), index_col='idx')\n",
    "code_15_labels['actual'] = code_15_labels[label_mapping.values()].apply(\n",
    "    lambda row: ', '.join(row.index[row]),\n",
    "    axis=1,\n",
    ")\n",
    "code_15_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predicted and actual labels side-by-side\n",
    "pred_thresh_mapped[['predicted']].join(code_15_labels[['actual']], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35",
   "metadata": {},
   "source": [
    "# 5. Extra - Load models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36",
   "metadata": {},
   "source": [
    "Outside of the scripts/hydra client, models can be easily loaded as shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fairseq_signals.models import build_model_from_checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_finetuned = build_model_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(root, 'notebooks/ckpts/physionet_finetuned.pt')\n",
    ")\n",
    "model_finetuned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run if the pretrained model hasn't already been downloaded\n",
    "from huggingface_hub import hf_hub_download\n",
    "\n",
    "_ = hf_hub_download(\n",
    "    repo_id='wanglab/ecg-fm-preprint',\n",
    "    filename='mimic_iv_ecg_physionet_pretrained.pt',\n",
    "    local_dir=os.path.join(root, 'noteboooks/ckpts'),\n",
    ")\n",
    "_ = hf_hub_download(\n",
    "    repo_id='wanglab/ecg-fm-preprint',\n",
    "    filename='mimic_iv_ecg_physionet_pretrained.yaml',\n",
    "    local_dir=os.path.join(root, 'notebooks/ckpts'),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pretrained = build_model_from_checkpoint(\n",
    "    checkpoint_path=os.path.join(root, 'notebooks/ckpts/mimic_iv_ecg_physionet_pretrained.pt')\n",
    ")\n",
    "model_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.9.21",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
